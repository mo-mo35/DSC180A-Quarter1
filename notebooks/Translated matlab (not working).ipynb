{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon, multivariate_normal\n",
    "from sympy import nextprime\n",
    "\n",
    "# Set the dimensions of the problem\n",
    "n = nextprime(20)  # size of observations\n",
    "d = nextprime(3)   # number of latent dimensions\n",
    "T = nextprime(1000)  # number of trials\n",
    "\n",
    "# Specify SNR and noise variance\n",
    "SNR = 0.5\n",
    "nseVar = d ** 2 / SNR\n",
    "\n",
    "# Generate data\n",
    "W = np.random.randn(n, d)  # weight matrix\n",
    "z = np.random.randn(d, T)  # latents\n",
    "lambda_ = expon.rvs(scale=1, size=(n,)) / nseVar  # noise precisions\n",
    "Y = W @ z + np.diag(np.sqrt(1.0 / lambda_)) @ np.random.randn(n, T)\n",
    "\n",
    "# Do EM (with help from Bishop)\n",
    "# initialize\n",
    "I = 1200  # number of iterations\n",
    "Wn = np.random.randn(n, d)  # Initialize new W\n",
    "lambNew = nseVar * expon.rvs(scale=1, size=(n,))  # initialize noise variances\n",
    "S = Y @ Y.T / T  # raw data sample covariance\n",
    "ll = np.empty(I)  # to store log-likelihoods\n",
    "\n",
    "for ii in range(I):\n",
    "    Wo = Wn\n",
    "    lambOld = lambNew\n",
    "    \n",
    "    # E-step\n",
    "    invPsiOld = np.diag(lambOld)\n",
    "    invG = np.eye(d) + Wo.T @ np.linalg.inv(invPsiOld) @ Wo\n",
    "    Ez = Wo.T @ np.linalg.inv(invPsiOld) @ Y\n",
    "    Ez = np.linalg.solve(invG, Ez)\n",
    "    sumEzz = T * np.linalg.inv(invG) + Ez @ Ez.T\n",
    "    \n",
    "    # M-step\n",
    "    Wn = Y @ Ez.T\n",
    "    Wn = np.linalg.solve(sumEzz, Wn.T).T\n",
    "    lambNew = 1.0 / np.diag(S - Wn @ Ez @ Y.T / T)\n",
    "    \n",
    "    # document progress\n",
    "    cov_matrix = Wn @ Wn.T + np.diag(1.0 / lambNew)\n",
    "    ll[ii] = np.sum(multivariate_normal.logpdf(Y.T, mean=np.zeros(n), cov=cov_matrix))\n",
    "\n",
    "# Verify we are getting the correct result\n",
    "WW = W @ W.T\n",
    "WnWn = Wn @ Wn.T\n",
    "pltclr = plt.cm.tab10(0)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Left plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.loglog([min(lambda_), max(lambda_)], [min(lambda_), max(lambda_)], 'k', linewidth=2)\n",
    "plt.scatter(lambda_, lambNew, edgecolor=pltclr, facecolor=pltclr, alpha=0.5)\n",
    "plt.title(r'$\\lambda$')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Estimated')\n",
    "plt.axis('equal')\n",
    "plt.grid(False)\n",
    "\n",
    "# Right plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([WW.min(), WW.max()], [WW.min(), WW.max()], 'k', linewidth=2)\n",
    "plt.scatter(WW.flatten(), WnWn.flatten(), edgecolor=pltclr, facecolor=pltclr, alpha=0.2)\n",
    "plt.title(r'$W W^T$')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Estimated')\n",
    "plt.axis('equal')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Verify marginal log-likelihood is increasing every step\n",
    "plt.figure()\n",
    "plt.loglog(range(1, I + 1), ll, '-o', linewidth=2)\n",
    "plt.ylabel('Marginal Log-likelihood')\n",
    "plt.xlabel('Iteration')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
